{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3226342b",
   "metadata": {},
   "source": [
    "# CSCI 5622: Machine Learning\n",
    "## Fall 2023\n",
    "### Instructor: Daniel Acuna, Associate Professor, Department of Computer Science, University of Colorado at Boulder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c3eab8",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "818d0b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"Luna McBride\"\n",
    "COLLABORATORS = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ea1645",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0303d5a1-96bd-4baf-bc7c-86572d7596b0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a3404bd56d3fda24286aab56807d28dd",
     "grade": false,
     "grade_id": "cell-a05ccabca6f911cc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Necessary imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a20a8376-fe74-47ff-b0ca-d7b719908492",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "67ea331d6f07f9b4767675aff00996bd",
     "grade": false,
     "grade_id": "cell-42bf5f824c2bb681",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "X = load_breast_cancer()['data']\n",
    "y = load_breast_cancer()['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "557be2a8-8fd7-426e-ba2d-8bbd061eb5cc",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fd2673d05f27dd3c96d0b57b81438f25",
     "grade": false,
     "grade_id": "cell-ee92b46718beabc2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5575ea42-7e1d-4526-aca4-b9eb76439de6",
   "metadata": {},
   "source": [
    "# Part 1: (45 pts) Entropy, information gain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bb8a4b-b789-4972-b6d0-698cc2b6de86",
   "metadata": {},
   "source": [
    "For all the questions in this part, consider that the features are binary and the label is binary as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ea32ec-8c93-4c15-90d5-bd434a1f5517",
   "metadata": {},
   "source": [
    "### (5 pts) Question 1: Entropy\n",
    "\n",
    "Entropy is a measure of the impurity or disorder of a dataset. For a binary classification problem, the entropy of a dataset $ D $ is given by:\n",
    "\n",
    "$$\n",
    "H(D) = - p_+ \\log_2 p_+ - p_- \\log_2 p_-\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $ p_+ $ is the proportion of positive examples in $ D $.\n",
    "- $ p_- $ is the proportion of negative examples in $ D $.\n",
    "\n",
    "If $ p_+ $ or $ p_- $ is $ 0 $, their respective term in the equation is considered to be $ 0 $ (since the logarithm of $ 0 $ is undefined).\n",
    "\n",
    "**Task:**\n",
    "\n",
    "Your task is to implement the entropy function based on the provided formula. Make sure to handle the edge cases where $ p_+ $ or $ p_- $ are $ 0 $.\n",
    "\n",
    "- Hint: Sometimes, you need to accept an empty set (`len(target) == 0`), and you should return 0 entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7516c337-6590-4a44-a5dd-0a107c9deb3a",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c3725618904aab86fb7520a75fc2edfe",
     "grade": false,
     "grade_id": "cell-7f0a98b07e361d36",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def entropy(target: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Compute the entropy of a dataset.\n",
    "    \n",
    "    Parameters:\n",
    "    - target: A 1D numpy array of shape (n_samples,) containing the binary target values (0 or 1).\n",
    "    \n",
    "    Returns:\n",
    "    - H: A float representing the entropy of the dataset.\n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    H = 0.0 #Set a baseline for the entropy value\n",
    "    \n",
    "    #If there are no values to check (ie, there are no positive nor negative values), return 0\n",
    "    if len(target) == 0:\n",
    "        return H #Return the default H of H=0\n",
    "    \n",
    "    positive = 0 #Initialize a counter for the number of positive entries\n",
    "    negative = 0 #Initialize a counter for the number of negative entries\n",
    "    number = len(target) #Get the length as the number of total entries\n",
    "    \n",
    "    #For each element, add to positive if positive and add to negative if negative\n",
    "    for element in target:\n",
    "        \n",
    "        #If the element is positive, add to positive\n",
    "        if element == 1:\n",
    "            positive += 1 #Add one to positive, as to count the number of positive entries\n",
    "        \n",
    "        #If the element is not positive, add to negative\n",
    "        else:\n",
    "            negative += 1 #Add one to negative\n",
    "            \n",
    "    positive = positive/number #Divide by the total number to get the proportion of positives\n",
    "    negative = negative/number #Divide by the total number to get the proportion of negatives\n",
    "    \n",
    "    #If there are no positives, just calculate negative.\n",
    "    if positive == 0:\n",
    "        H = -1 * negative * np.log2(negative) #Calculate the entropy for just the negative values\n",
    "    \n",
    "    #If there are no negatives, just calculate positive.\n",
    "    elif negative == 0:\n",
    "        H = -1 * positive * np.log2(positive) #Calculate the entropu for jusy positive values\n",
    "        \n",
    "    #If there are both positive and negative values, compute the entropy properly\n",
    "    else:\n",
    "        H = (-1 * positive * np.log2(positive)) - (negative * np.log2(negative)) #Compute the entropu by the given equation\n",
    "    \n",
    "    return H #Return the entropy value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5840aef9-4984-4c1c-94ef-b3ed21b5d222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9182958340544896"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some examples\n",
    "entropy(np.array([0, 1, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da502424-e7e5-46f2-922c-481097fe58e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy(np.array([0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba77ca2e-fefd-4f0c-95be-b6a63379f5d8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1346b871e20099a09f8bcca71ca598a7",
     "grade": true,
     "grade_id": "cell-a9ce770436c346b7",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test with a balanced dataset\n",
    "y_test_1 = np.array([0, 1, 0, 1])\n",
    "assert np.isclose(entropy(y_test_1), 1.0, atol=1e-5), \"Test Case 1 Failed\"\n",
    "# Test with all negative examples\n",
    "y_test_2 = np.array([0, 0, 0, 0])\n",
    "assert np.isclose(entropy(y_test_2), 0.0, atol=1e-5), \"Test Case 2 Failed\"\n",
    "# Test with all positive examples\n",
    "y_test_3 = np.array([1, 1, 1, 1])\n",
    "assert np.isclose(entropy(y_test_3), 0.0, atol=1e-5), \"Test Case 3 Failed\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d936ded8-59c0-4936-8b90-8bdd7443165f",
   "metadata": {},
   "source": [
    "## (10 pts) Question 2: Information Gain\n",
    "\n",
    "Information Gain (IG) is a measure of the effectiveness of an attribute in classifying the training data. It calculates the difference between the entropy of the dataset before the split and the weighted entropy of each branch after the split. The formula for computing IG is given by:\n",
    "\n",
    "$$\n",
    "IG(D, A) = H(D) - \\sum_{v \\in A} \\left( \\frac{|D_v|}{|D|} \\times H(D_v) \\right)\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $ H(D) $ is the entropy of the dataset.\n",
    "- $ A $ is the attribute or feature column we're considering.\n",
    "- $ D_v $ is the subset of data for which attribute $ A $ has value $ v $.\n",
    "- $ |D_v| $ is the number of samples in $ D_v $.\n",
    "- $ |D| $ is the total number of samples.\n",
    "\n",
    "**Task:**\n",
    "\n",
    "Write a function `information_gain` to solve the problem.\n",
    "\n",
    "Hint:\n",
    "1. Start by computing the entropy of the dataset before the split.\n",
    "2. Next, compute the weighted entropy of each branch after the split based on the feature column $x_j \\leq v$ \n",
    "3. Return the difference between the initial entropy and the weighted sum of branch entropies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4490a415-d044-423e-9c84-bbc14e5b283f",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "94fb5ed29f21f15ae67429395c72fa53",
     "grade": false,
     "grade_id": "cell-6faa057efca41ff7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def information_gain(X: np.ndarray, y: np.ndarray, j: int, v: float) -> float:\n",
    "    \"\"\"\n",
    "    Compute the information gain of splitting the data based on feature column j.\n",
    "    \n",
    "    Parameters:\n",
    "    - X: A 2D numpy array of shape (n_samples, n_features) containing the features\n",
    "    - y: A 1D numpy array of shape (n_samples,) containing the binary target values (0 or 1).\n",
    "    - j: An integer representing the target feature column index (0-indexed).\n",
    "    - v: A floating point containing the value by which this column will be split\n",
    "    \n",
    "    Returns:\n",
    "    - IG: A float representing the information gain of the split based on feature column j.\n",
    "    \"\"\"    \n",
    "    # YOUR CODE HERE\n",
    "    entropyAllData = entropy(y) #Get the entropy on all of the data\n",
    "    \n",
    "    combinedXY = list(zip(X, y)) #Combining X and y so they stay connected, even through any subsets or randomization\n",
    "    #I learned this I do not know how many years ago at this point, but it is still one of the best ways to make sure that xy connection is not lost\n",
    "    \n",
    "    Xlower = [] #Initialize a list for the x values of the lower than v split\n",
    "    ylower = [] #Initialize a list for the y values of the lower than v split\n",
    "    Xupper = [] #Initialize a list for the x values of the higher than v split\n",
    "    yupper = [] #Initialize a list for the y values of the higher than v split\n",
    "    \n",
    "    #For each features and y value pair, determine if it is part of the lower or upper split\n",
    "    for Xvalue, yvalue in combinedXY:\n",
    "        \n",
    "        #If the value selected is less than or equal to v, add it to the lower lists \"based on the feature column  𝑥𝑗≤𝑣\"\n",
    "        if Xvalue[j] <= v:\n",
    "            Xlower.append(Xvalue) #Add the x features to the lower x list\n",
    "            ylower.append(yvalue) #Add the y value to the lower y list\n",
    "        \n",
    "        #If the value selected is strictly greater than v, add it to the upper lists\n",
    "        else:\n",
    "            Xupper.append(Xvalue) #Add the x features to the upper x list\n",
    "            yupper.append(yvalue) #Add the y value to the upper y list\n",
    "    \n",
    "    lowerHalfSum = (len(Xlower)/len(X)) * entropy(ylower) #Get the len dv / len x * entropy for the lower than v values\n",
    "    upperHalfSum = (len(Xupper)/len(X)) * entropy(yupper) #Get the len dv / len x * entropy for the higher than v values\n",
    "    \n",
    "    IG = entropyAllData - lowerHalfSum - upperHalfSum #Calculate the overall summation from the equation above\n",
    "    \n",
    "    return IG #Return the summation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d8fec9e-0b02-4e6b-bde0-8b04dbbcae8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy(y_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9dfc89bb-a5bc-44d4-8144-0d90b2402b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try your function here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad352ea5-2694-4dab-a500-c3aa2eb4bf16",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9fad0bd08429bdaa17a74a631a61fb9e",
     "grade": true,
     "grade_id": "cell-6d36fe1ad1e52f2f",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" (10 pts) \"\"\"\n",
    "# Test Case 1: Binary Feature\n",
    "X_test_1 = np.array([\n",
    "    [0, 1],\n",
    "    [1, 0],\n",
    "    [1, 1],\n",
    "    [0, 0]\n",
    "])\n",
    "y_test_1 = np.array([0, 1, 0, 1])\n",
    "# Given that the threshold doesn't matter for binary features, we can still provide one\n",
    "assert np.isclose(information_gain(X_test_1, y_test_1, 1, 0.5), 1.0, atol=1e-5), \"Test Case 1 Failed\"\n",
    "\n",
    "# Test Case 2: Continuous Feature\n",
    "X_test_2 = np.array([\n",
    "    [0.5, 1.5],\n",
    "    [1.5, 0.5],\n",
    "    [2.5, 1.5],\n",
    "    [0.5, 0.5]\n",
    "])\n",
    "y_test_2 = np.array([0, 1, 0, 1])\n",
    "# Here, the threshold matters; we're checking the information gain when the split is made at 1.0 for feature 1\n",
    "assert np.isclose(information_gain(X_test_2, y_test_2, 1, 1.0), 1.0, atol=1e-5), \"Test Case 2 Failed\"\n",
    "\n",
    "# Test Case 3: Another Continuous Feature\n",
    "X_test_3 = np.array([\n",
    "    [0.5, 1.5, 2.5],\n",
    "    [1.5, 0.5, 2.5],\n",
    "    [2.5, 1.5, 1.5],\n",
    "    [0.5, 0.5, 0.5]\n",
    "])\n",
    "y_test_3 = np.array([0, 1, 0, 1])\n",
    "# Checking the information gain for a split made at 2.0 for feature 2\n",
    "expected_IG_3 = 0.31127812445913283\n",
    "assert np.isclose(information_gain(X_test_3, y_test_3, 2, 1.0), expected_IG_3, atol=1e-5), \"Test Case 3 Failed\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31feb6d-4829-4f1d-a6bd-59b22d18191d",
   "metadata": {},
   "source": [
    "### (10 pts) Question 3: Create a Function Representing a \"Decision Stump\"\n",
    "\n",
    "A decision stump is a decision tree with just one split. It makes a decision based on whether a feature \\(j\\) is less than or equal to a value \\(v\\), and returns a specified value if the condition is met.\n",
    "\n",
    "**Task:**\n",
    "\n",
    "Write a function `create_decision_stump` with the following signature:\n",
    "\n",
    "```python\n",
    "def create_decision_stump(j: int, threshold: float, return_value: int) -> Callable[[np.ndarray], np.ndarray]:\n",
    "    \"\"\"\n",
    "    Create a decision stump based on feature column j, a threshold value, and a specified return value if \n",
    "    the condition is met.\n",
    "    \n",
    "    Parameters:\n",
    "    - j: An integer representing the feature column index (0-indexed) to base the decision on.\n",
    "    - threshold: A float representing the threshold value to decide the split.\n",
    "    - return_value: An integer (0 or 1) to return when the feature column value is less than or equal to the threshold.\n",
    "    \n",
    "    Returns:\n",
    "    - decision_stump: A function that takes in a 2D numpy array and returns a 1D numpy array\n",
    "                      with predictions, returning the specified value if the feature column value is less than or \n",
    "                      equal to the threshold, and the opposite value otherwise.\n",
    "    \"\"\"\n",
    "    pass\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e300a45-bfe9-4f9a-b080-3496f372b0a9",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7a4f6c0574149433c87076fcbca4002c",
     "grade": false,
     "grade_id": "cell-1690921dca462a27",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "def create_decision_stump(j: int, threshold: float, return_value: int) -> Callable[[np.ndarray], np.ndarray]:\n",
    "    \"\"\"\n",
    "    Create a decision stump based on feature column j, a threshold value, and a specified return value if \n",
    "    the condition is met.\n",
    "    \n",
    "    Parameters:\n",
    "    - j: An integer representing the feature column index (0-indexed) to base the decision on.\n",
    "    - threshold: A float representing the threshold value to decide the split.\n",
    "    - return_value: An integer (0 or 1) to return when the feature column value is less than or equal to the threshold.\n",
    "    \n",
    "    Returns:\n",
    "    - decision_stump: A function that takes in a 2D numpy array and returns a 1D numpy array\n",
    "                      with predictions, returning the specified value if the feature column value is less than or \n",
    "                      equal to the threshold, and the opposite value otherwise.\n",
    "    \"\"\"\n",
    "    \n",
    "    def decision_stump(x):\n",
    "        \"\"\"\n",
    "        Create a decision stump based the values in the external function and an additional pass-in x.\n",
    "    \n",
    "        Parameters:\n",
    "        - x: a list of features from which to follow the j, threshold, and return_value rules from the external function\n",
    "    \n",
    "        Returns:\n",
    "        - returnValues: a list of outputs to be expected from the stump for each feature list in x\n",
    "        \"\"\"\n",
    "        returnValues = [] #Create the returnValues list\n",
    "        \n",
    "        #For each set of values in x, check the specified j and threshold values and append the appropriate return value\n",
    "        for values in x:\n",
    "            #If the value at the specified j is less than or equal to the threshold, append the return value\n",
    "            if values[j] <= threshold:\n",
    "                returnValues.append(return_value) #Append the return value to the returnValues list\n",
    "                \n",
    "            #If the value at the specified j is strictly greater than the threshold, apply the opposite of the return value\n",
    "            else:\n",
    "                returnValues.append(int(not return_value)) #Append the opposite of the return value (1->0, 0->1)\n",
    "        \n",
    "        return returnValues #Return the return values\n",
    "        \n",
    "    \n",
    "    return decision_stump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "539f2638-5ea8-4d21-a7a6-640a63707296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try it here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85e2ecda-7fed-4e0c-bfa6-3ecb44dfd0b6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "962b2897cbeca0e192417314f7e9d1a2",
     "grade": true,
     "grade_id": "cell-67f4738a744a9dd5",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"(10 pts) Some tests\"\"\"\n",
    "# Test Case 1: Binary Feature\n",
    "X_test_1 = np.array([\n",
    "    [0, 1],\n",
    "    [1, 0],\n",
    "    [1, 1],\n",
    "    [0, 0]\n",
    "])\n",
    "# Here, we expect all values less than or equal to 0 to be classified as 1, and others as 0\n",
    "stump_1 = create_decision_stump(0, 0, 1)\n",
    "assert np.array_equal(stump_1(X_test_1), np.array([1, 0, 0, 1])), \"Test Case 1 Failed\"\n",
    "\n",
    "# Test Case 2: Continuous Feature\n",
    "X_test_2 = np.array([\n",
    "    [0.5, 1.5],\n",
    "    [1.5, 0.5],\n",
    "    [2.5, 1.5],\n",
    "    [0.5, 0.5]\n",
    "])\n",
    "# We're checking the predictions when the split is made at 1.0 for feature 1\n",
    "# Values less than or equal to 1.0 should be classified as 0, and others as 1\n",
    "stump_2 = create_decision_stump(1, 1.0, 0)\n",
    "assert np.array_equal(stump_2(X_test_2), np.array([1, 0, 1, 0])), \"Test Case 2 Failed\"\n",
    "\n",
    "# Test Case 3: Another Continuous Feature\n",
    "X_test_3 = np.array([\n",
    "    [0.5, 1.5, 2.5],\n",
    "    [1.5, 0.5, 2.5],\n",
    "    [2.5, 1.5, 1.5],\n",
    "    [0.5, 0.5, 0.5]\n",
    "])\n",
    "# Checking the predictions for a split made at 2.0 for feature 2\n",
    "# Values less than or equal to 2.0 should be classified as 0, and others as 1\n",
    "stump_3 = create_decision_stump(2, 2.0, 0)\n",
    "assert np.array_equal(stump_3(X_test_3), np.array([1, 1, 0, 0])), \"Test Case 3 Failed\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f49c0c2-3267-4a36-bfb1-815ec84c2fda",
   "metadata": {},
   "source": [
    "### (10 pts) Question 4: Best Feature to Split By\n",
    "\n",
    "Using the previously defined `information_gain` function that now takes a threshold as a parameter, your task is to find the best feature and threshold to split the data on. Specifically, you should identify the feature and threshold that provides the highest information gain when used as a decision stump.\n",
    "\n",
    "**Task:**\n",
    "\n",
    "Write a function `best_feature_to_split` with the following signature:\n",
    "\n",
    "```python\n",
    "def best_feature_to_split(X: np.ndarray, y: np.ndarray) -> Tuple[int, float]:\n",
    "    \"\"\"\n",
    "    Identify the best feature and threshold to split the dataset on based on information gain.\n",
    "    \n",
    "    Parameters:\n",
    "    - X: A 2D numpy array of shape (n_samples, n_features) containing the features.\n",
    "    - y: A 1D numpy array of shape (n_samples,) containing the binary target values (0 or 1).\n",
    "    \n",
    "    Returns:\n",
    "    - j_best: An integer representing the index (0-indexed) of the best feature column to split on.\n",
    "    - v_best: A float representing the best threshold to split the feature by.\n",
    "    \"\"\"\n",
    "    pass\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3abb37a9-7938-4d74-9658-7069a517f57c",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "92a59d3038ba8ed11fc753c50abbb3d2",
     "grade": false,
     "grade_id": "cell-dc6d3397133b0bf7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "def best_feature_to_split(X: np.ndarray, y: np.ndarray) -> Tuple[int, float]:\n",
    "    \"\"\"\n",
    "    Identify the best feature and threshold to split the dataset on based on information gain.\n",
    "    \n",
    "    Parameters:\n",
    "    - X: A 2D numpy array of shape (n_samples, n_features) containing the features.\n",
    "    - y: A 1D numpy array of shape (n_samples,) containing the binary target values (0 or 1).\n",
    "    \n",
    "    Returns:\n",
    "    - j_best: An integer representing the index (0-indexed) of the best feature column to split on.\n",
    "    - v_best: A float representing the best threshold to split the feature by.\n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    minValue = 20000000000000000 #Set an arbitrarily large min value to not potentially overlap with actually small min values\n",
    "    maxValue = -20000000000000000 #Set an arbitrarily small max value to not potentially overlap with actually large max values\n",
    "    \n",
    "    #For each set of values, find the min and max. If they are the global min or max, update the global min or max respectively\n",
    "    for values in X:\n",
    "        \n",
    "        #If the min in this set is the actual min, set the min value to the new minimum\n",
    "        if min(values) < minValue:\n",
    "            minValue = min(values) #Set the min value to the new minimum\n",
    "            \n",
    "        #If the max in this set is the actual max, set the max value to the new maximum\n",
    "        if max(values) > maxValue:\n",
    "            maxValue = max(values) #Set the max value to the new maximum\n",
    "            \n",
    "    #For each item in the range min*10 to max*10 (since range only works with whole numbers and all values so far have been to\n",
    "    #  one decimal place), divide it by 10 to fit it back into the proper single decimal place value. The minimum and maximum\n",
    "    #  values are used here to ensure the thresholds are properly limited between the possible values in the set.\n",
    "    thresholds = [item/10 for item in list(range(int(minValue*10), int(maxValue*10)))]\n",
    "    features = range(0, len(X[0])) #Create a feature list for the length of possible features\n",
    "    \n",
    "    j_best = -1 #Initialize the best feature to -1, as no feature has been selected yet\n",
    "    v_best = -200000000000000000 #Initialize the best threshold to an arbitrarily small number so it cannot be mistaken for an actual threshold\n",
    "    informationGain = -100000000000 #Initialize the information gain to an arbitrarily small number to to overlap with actual gains\n",
    "    \n",
    "    #For each feature and each threshold, check the information gain to determine the best\n",
    "    for feature in features:\n",
    "        \n",
    "        #For each threshold and feature, check the information gain to determine the best\n",
    "        for threshold in thresholds:\n",
    "            gain = information_gain(X, y, feature, threshold) #Get the gain of the current feature/threshold pair\n",
    "            \n",
    "            #If this gain is better than the current best gain, update the gain along with the current best values\n",
    "            if gain > informationGain:\n",
    "                informationGain = gain #Update the best gain to the current gain\n",
    "                v_best = threshold #Update the best threshold to the current threshold\n",
    "                j_best = feature #Update the best feature to the current feature\n",
    "    \n",
    "    return j_best, v_best #Return the best feature and threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fdd97882-c6ce-4491-8c37-4f44c2356480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.0\n"
     ]
    }
   ],
   "source": [
    "# try it here\n",
    "# Why wouldn't I use one of the tests to test the values? it is clearly stated in the test what this should be\n",
    "X_test_1 = np.array([\n",
    "    [0, 1],\n",
    "    [1, 0],\n",
    "    [1, 1],\n",
    "    [0, 0]\n",
    "])\n",
    "y_test_1 = np.array([0, 1, 0, 1])\n",
    "best_feature_1, best_threshold_1 = best_feature_to_split(X_test_1, y_test_1)\n",
    "print(best_feature_1, best_threshold_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7fd7abd4-9372-4d11-89f8-320161d6f872",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "29c6f2863f1ec957f3f870783a711b1a",
     "grade": true,
     "grade_id": "cell-8d53364adc0cb1dc",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" (10 pts)  \"\"\"\n",
    "# Test Case 1: Basic Test with Binary Features\n",
    "X_test_1 = np.array([\n",
    "    [0, 1],\n",
    "    [1, 0],\n",
    "    [1, 1],\n",
    "    [0, 0]\n",
    "])\n",
    "y_test_1 = np.array([0, 1, 0, 1])\n",
    "best_feature_1, best_threshold_1 = best_feature_to_split(X_test_1, y_test_1)\n",
    "# Either feature provides no information gain as both have an equal number of 0s and 1s\n",
    "# The threshold doesn't matter for binary features\n",
    "assert best_threshold_1 in [0, 1], \"Test Case 1 Failed\"\n",
    "\n",
    "# Test Case 2: Continuous Features\n",
    "X_test_2 = np.array([\n",
    "    [0.5, 1.5],\n",
    "    [1.5, 0.5],\n",
    "    [2.5, 1.5],\n",
    "    [0.5, 0.5]\n",
    "])\n",
    "y_test_2 = np.array([0, 1, 0, 1])\n",
    "best_feature_2, best_threshold_2 = best_feature_to_split(X_test_2, y_test_2)\n",
    "# The second feature provides the maximum information gain when split at 1.0\n",
    "assert best_feature_2 == 1 and np.isclose(best_threshold_2, 0.5, atol=1e-5), \"Test Case 2 Failed\"\n",
    "\n",
    "# Test Case 3: Mixed Binary and Continuous Features\n",
    "X_test_3 = np.array([\n",
    "    [1, 0.5],\n",
    "    [0, 1.5],\n",
    "    [0, 0.5],\n",
    "    [1, 2.5]\n",
    "])\n",
    "y_test_3 = np.array([1, 0, 1, 0])\n",
    "best_feature_3, best_threshold_3 = best_feature_to_split(X_test_3, y_test_3)\n",
    "# The second feature provides the maximum information gain when split at 1.5\n",
    "assert best_feature_3 == 1 and np.isclose(best_threshold_3, 0.5, atol=1e-5), \"Test Case 3 Failed\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f4e9c2-5d4e-44fd-8421-fc5be7f5d28b",
   "metadata": {},
   "source": [
    "### Question 5: (10 pts) Fitting a Decision Stump with a Threshold\n",
    "\n",
    "Now that you have the tools to identify the best feature and threshold to split on, and to create a decision stump based on a given feature and threshold, your task is to combine these tools to fit a decision stump to a given dataset.\n",
    "\n",
    "**Task:**\n",
    "\n",
    "Write a function `fit_decision_stump` with the following signature:\n",
    "\n",
    "```python\n",
    "def fit_decision_stump(X: np.ndarray, y: np.ndarray) -> Callable[[np.ndarray], np.ndarray]:\n",
    "    \"\"\"\n",
    "    Fit a decision stump to the dataset and return the stump function, considering the best threshold for the split.\n",
    "    \n",
    "    Parameters:\n",
    "    - X: A 2D numpy array of shape (n_samples, n_features) containing the features.\n",
    "    - y: A 1D numpy array of shape (n_samples,) containing the binary target values (0 or 1).\n",
    "    \n",
    "    Returns:\n",
    "    - stump: A function that takes in a 2D numpy array and returns a 1D numpy array\n",
    "             with predictions based on the best feature and threshold split.\n",
    "    \"\"\"\n",
    "    pass\n",
    "```\n",
    "\n",
    "Use the `best_feature_to_split` function to determine the best feature and threshold to split on. Then, use the `create_decision_stump` function to create the decision stump based on that feature and threshold. The returned `stump` function should be callable with a 2D numpy array (the dataset) and should return a 1D numpy array with the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e19e4de2-63f3-414b-9b67-16d82c6b425c",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6a103864a589e59608c49a3d7f4861ba",
     "grade": false,
     "grade_id": "cell-5203353f59f8440f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import mode\n",
    "\n",
    "def fit_decision_stump(X: np.ndarray, y: np.ndarray) -> Callable[[np.ndarray], np.ndarray]:\n",
    "    \"\"\"\n",
    "    Fit a decision stump to the dataset and return the stump function, considering the best threshold for the split.\n",
    "    \n",
    "    Parameters:\n",
    "    - X: A 2D numpy array of shape (n_samples, n_features) containing the features.\n",
    "    - y: A 1D numpy array of shape (n_samples,) containing the binary target values (0 or 1).\n",
    "    \n",
    "    Returns:\n",
    "    - stump: A function that takes in a 2D numpy array and returns a 1D numpy array\n",
    "             with predictions based on the best feature and threshold split.\n",
    "    \"\"\"\n",
    "    bestJ, bestThresh = best_feature_to_split(X, y) #Get the best threshold and feature to split from best_feature_to_split\n",
    "    bestStump = create_decision_stump(bestJ, bestThresh, 1) #Get a best stump using the best feature and threshold\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    def stump(x):\n",
    "        \"\"\"\n",
    "        Get predictions from the almighty best stump for a given array x\n",
    "    \n",
    "        Parameters:\n",
    "        - x: A 2D numpy array of shape (n_samples, n_features) containing the features to predict from\n",
    "    \n",
    "        Returns:\n",
    "        - The predictions from the best stump\n",
    "        \"\"\"\n",
    "        return bestStump(x) #Return the predictions from the best stump given the x array to predict\n",
    "    \n",
    "    return stump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b315c30e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "X_test_2 = np.array([\n",
    "    [0.5, 1.5],\n",
    "    [1.5, 0.5],\n",
    "    [2.5, 1.5],\n",
    "    [0.5, 0.5]\n",
    "])\n",
    "y_test_2 = np.array([0, 1, 0, 1])\n",
    "stump_2 = fit_decision_stump(X_test_2, y_test_2)\n",
    "print(stump_2(X_test_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3d8951a6-e88b-46d5-a25e-c745428880be",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b2bad7ae90a8fe9a6206bf48f0458421",
     "grade": true,
     "grade_id": "cell-8faa788386035e92",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" (20 pts) tests\"\"\"\n",
    "# Test Case 1: Binary Features\n",
    "X_test_1 = np.array([\n",
    "    [0, 1],\n",
    "    [1, 0],\n",
    "    [1, 1],\n",
    "    [0, 0]\n",
    "])\n",
    "y_test_1 = np.array([0, 1, 0, 1])\n",
    "stump_1 = fit_decision_stump(X_test_1, y_test_1)\n",
    "# Since both features are equally good for splitting (information gain is 0 for both),\n",
    "# it can choose either, and the threshold doesn't matter for binary features\n",
    "predictions_1 = stump_1(X_test_1)\n",
    "assert np.array_equal(predictions_1, y_test_1) or np.array_equal(predictions_1, 1 - y_test_1), \"Test Case 1 Failed\"\n",
    "\n",
    "# Test Case 2: Continuous Features\n",
    "X_test_2 = np.array([\n",
    "    [0.5, 1.5],\n",
    "    [1.5, 0.5],\n",
    "    [2.5, 1.5],\n",
    "    [0.5, 0.5]\n",
    "])\n",
    "y_test_2 = np.array([0, 1, 0, 1])\n",
    "stump_2 = fit_decision_stump(X_test_2, y_test_2)\n",
    "# The best split is at feature 1 with threshold 1.0\n",
    "# Values <= 1.0 are classified as 1, and others as 0\n",
    "assert np.array_equal(stump_2(X_test_2), np.array([0, 1, 0, 1])), \"Test Case 2 Failed\"\n",
    "\n",
    "# Test Case 3: Mixed Binary and Continuous Features\n",
    "X_test_3 = np.array([\n",
    "    [1, 0.5],\n",
    "    [0, 1.5],\n",
    "    [0, 0.5],\n",
    "    [1, 2.5]\n",
    "])\n",
    "y_test_3 = np.array([1, 0, 1, 0])\n",
    "stump_3 = fit_decision_stump(X_test_3, y_test_3)\n",
    "# The best split is at feature 1 with threshold 1.5\n",
    "# Values <= 1.5 are classified as 1, and others as 0\n",
    "assert np.array_equal(stump_3(X_test_3), np.array([1, 0, 1, 0])), \"Test Case 3 Failed\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc271f7d-c2e2-4dc4-b467-3a17583b132f",
   "metadata": {},
   "source": [
    "#### Question 5.1: (5 pts) Estimate the performance of decision stump\n",
    "\n",
    "Use the `X_train` and `y_train` data to fit your decision stump and call it `model0`. Estimate the performance of the model on the testing data and store it in `accuracy0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "95f84d74-45b1-4f6c-9535-b710836676c3",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4887727bb15955870ec53f8f196fe22b",
     "grade": false,
     "grade_id": "cell-23f27e00aba769e1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to fit: 5.443146793047587 minutes.\n",
      "Accuracy of decision stump 0.9263157894736842 vs. accuracy of majority vote model 0.656140350877193\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "import time #Import time to show how long this takes\n",
    "from sklearn.metrics import accuracy_score #Show the accuracy score\n",
    "start = time.time() #Start the timer\n",
    "model0 = fit_decision_stump(X_train, y_train) #Fit the stump\n",
    "end = time.time() #End the timer\n",
    "print(f\"Time taken to fit: {(end - start)/60} minutes.\")\n",
    "\n",
    "predStump = model0(X_test) #Create predictions\n",
    "accuracy0 = accuracy_score(predStump, y_test) #Get the accuracy of the stump\n",
    "print(f\"Accuracy of decision stump {accuracy0} vs. accuracy of majority vote model {((np.mean(y_test)**(np.mean(y_test) > 0.5))*((1-np.mean(y_test))**(np.mean(y_test) <= 0.5)))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "da16fcf6-f67d-4ab8-825d-e449c8ef459d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c8e4c0b8194a74c3e3dd0e4e7b4d02d7",
     "grade": true,
     "grade_id": "cell-4ccd2817ec6cf47e",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" (5 pts) \"\"\"\n",
    "assert accuracy0 > 0.7\n",
    "assert callable(model0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c87baa-8f66-47c5-9f4c-6398819f158b",
   "metadata": {},
   "source": [
    "### Question 6: (5 pts) Majority vote of set of stumps\n",
    "\n",
    "Create a function that returns a list of decision stumps and returns a function that produces the majority vote of the stumps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a9c1a630-612b-45b8-b213-5e2c2d5499bd",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "69c854bf8fce1fd4b964d6f8460793f1",
     "grade": false,
     "grade_id": "cell-993dccda2bf84467",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "def majority_vote_rule(stumps):\n",
    "    \"\"\"\n",
    "    Let the counsel of stumps decide the fate of the arbitrary values to test\n",
    "    \n",
    "    Parameters:\n",
    "    - stumps: A 1D numpy array of shape (n_stumps,) containing a list of stumps\n",
    "    \n",
    "    Returns:\n",
    "    - majority_stump: A function that takes in a 2D numpy array and returns a 1D numpy array\n",
    "             with predictions based on the counsel of stumps\n",
    "    \"\"\"\n",
    "    def majority_stump(x):\n",
    "        \"\"\"\n",
    "        Let the counsel of stumps decide the labels of the given features\n",
    "    \n",
    "        Parameters:\n",
    "        - x: A 2D numpy array of shape (n_samples, n_features) containing the features.\n",
    "    \n",
    "        Returns:\n",
    "        - actualPred: the rulings for the labels from the counsel of stumps\n",
    "        \"\"\"\n",
    "        predictions = [] #Create a list to hold the prediction lists\n",
    "        \n",
    "        #For each stump, generate predictions\n",
    "        for stump in stumps:\n",
    "            predictions.append(stump(x)) #Add the predictions to the predictions list\n",
    "        \n",
    "        numPredictions = len(x) #Get the number of predictions there are\n",
    "        actualPred = np.zeros(numPredictions) #Create a numpy array full of zeros of the total number of predictions\n",
    "        \n",
    "        #For each prediction list, add it to the actual prediction array\n",
    "        for pred in predictions:\n",
    "            pred = np.array(pred) #Turn into a numpy array to leverage its power\n",
    "            actualPred += pred #Add each element together in the array\n",
    "        \n",
    "        actualPred /= len(stumps) #Divide the summed predictions by the number of stumps the predictions came from, simulating a vote\n",
    "        actualPred = np.round(actualPred) #Round the values, as rounding up at 0.5 simulates having a majority\n",
    "        return actualPred.astype(int) #Return the actual predictions as an array of integers\n",
    "        \n",
    "    return majority_stump #Return the majority stump function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "167abdac-85db-4267-8f59-062881f4d2c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy predictions: [1 0 0 1 1 0 0 0 1 1 1 0 1 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0\n",
      " 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0 1 1 1 0 1 0\n",
      " 1 1 1 1 1 1 0 1 1 0 0 0 1 0 1 1 1 1 1 1 1 1 0 0 1 0 0 1 0 0 1 1 1 0 1 1 0\n",
      " 1 1 0 1 0 1 1 1 0 1 1 1 0 1 0 0 1 1 0 0 0 1 1 1 0 1 1 1 0 1 0 1 1 1 1 0 0\n",
      " 1 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0\n",
      " 1 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1\n",
      " 0 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1\n",
      " 0 1 1 1 0 0 1 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "dummy_model = majority_vote_rule([model0, model0])\n",
    "print(f\"Dummy predictions: {dummy_model(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a7ea6106-fafc-4ff4-b0fc-fcd02b7a98db",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "63c4942a3ec33652c51c554a378bf26b",
     "grade": true,
     "grade_id": "cell-18292be639d22949",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" (5 pts) \"\"\"\n",
    "assert callable(majority_vote_rule([model0]))\n",
    "assert callable(majority_vote_rule([model0, model0]))\n",
    "assert callable(majority_vote_rule([model0, model0, model0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb0b924-7f03-47d2-9ebd-5a7c4901c874",
   "metadata": {},
   "source": [
    "## Question 7: (10 pts) Tree bagging\n",
    "\n",
    "For k in [1, 20, 40, 60, 80, 100]:\n",
    "  - create $k$ bootstrap samples of the training data `X_train` and `y_train` and fit a decision tree stump.\n",
    "  - create majority vote classifier based on the set of decision stumps\n",
    "  - estimate the accuracy of the model on the testing data\n",
    "\n",
    "Plot `k` versus accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "936002bf-07b7-4b8d-ae43-6a931cabcfd3",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "455a15705cba39f5acd9319198ae6222",
     "grade": false,
     "grade_id": "cell-4c0be5b1f8432943",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 bootstrap samples\n",
      "Fitting 20 bootstrap samples\n",
      "Fitting 40 bootstrap samples\n",
      "Fitting 60 bootstrap samples\n",
      "Fitting 80 bootstrap samples\n",
      "Fitting 100 bootstrap samples\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "accuracy_list = []\n",
    "k_list = [1, 20, 40, 60, 80, 100]\n",
    "stumps = []\n",
    "for k in k_list:\n",
    "    print(f\"Fitting {k} bootstrap samples\")\n",
    "    # YOUR CODE HERE\n",
    "    samples = resample(X_train, y_train, n_samples = k, random_state = 42) #Get k samples from the resample method\n",
    "    stumps.append(fit_decision_stump(samples[0], samples[1])) #Add the stump to the counsel of stumps\n",
    "    theCounsel = majority_vote_rule(stumps) #Get the counsel together\n",
    "    accuracy_list.append(accuracy_score(theCounsel(X_test), y_test)) #Get the accuracy of the counsel's decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8b966fff-1919-497c-86d8-ecf4d1d4bfec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'accuracy')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(k_list, accuracy_list)\n",
    "plt.xlabel('number of bootstrap samples')\n",
    "plt.ylabel('accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "67b0e5be-72de-44cf-9f1c-5d14e6e0b4df",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "11fc3acfbc43fdba5ebd2b3284f077bd",
     "grade": true,
     "grade_id": "cell-1078d923f4abc88c",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" (10 pts) \"\"\"\n",
    "# Calculating the components needed for the slope formula\n",
    "n = len(k_list)\n",
    "sum_x = np.sum(k_list)\n",
    "sum_y = np.sum(accuracy_list)\n",
    "sum_xy = np.sum(np.array(k_list) * np.array(accuracy_list))\n",
    "sum_x_squared = np.sum(np.array(k_list)**2)\n",
    "\n",
    "# Calculating the slope\n",
    "m = (n * sum_xy - sum_x * sum_y) / (n * sum_x_squared - sum_x**2)\n",
    "\n",
    "# slope should at least not be negative\n",
    "assert m > -0.05"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
